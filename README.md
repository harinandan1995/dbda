# Deep Building Design Assistant (DBDA)

Code to generate a realistic 3D model given the shape of the building.

## Usage

### Packages

Before executing the code a few python packages have to be installed. Below are two of the best ways to install a virtual env to make sure you dont have conflicting packages installed in your system 

#### Virtualenv

Run the following commands to setup a virtual environment and install the packages in this environment 

Install **pip** first

    sudo apt-get install python3-pip

Then install **virtualenv** using pip3

    sudo pip3 install virtualenv 

Now create a virtual environment 

    virtualenv venv 

> you can use any name instead of **venv**

Active your virtual environment   
    
    source venv/bin/activate
    
Install necessary packages

    pip3 install -r requirements.txt

#### Conda

Install the latest version of conda with python3.7 support from [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/)

After conda is installed run the following commands to setup a virtual environment.

Create a virtual environment named venv

    conda create -n venv
    
Activate the virtual environment

    conda activate venv
   
Install the packages from requirements.txt
    
    conda install --file requirements.txt

Run ```which python``` and it should point to the python from the virtual environment. 

### Dataset

The dataset for the model is generated by transforming the vector files provided by [Raster-to-Vector](http://art-programmer.github.io/floorplan-transformation/paper.pdf)
which contains positions of various building elements and room types in a txt file.

Run the following command to transform these vector files into either *tfrecords* or *hdf5* or *png*

    python3 transform.py --config {path_to_the_config}
    
> Default config used is [config/transform.yaml](config/transform.yaml)
>> Each parameter is explained in detail in the yaml file

Note: png files are just for visualization and is not a valid data for training the model

> A already filtered and transformed dataset is available at [datasets/256](datasets/256) which can be directly used to train the models as shown below

### Generator training with GLO

Architecture used for this step is inspired from [Pix2Pix](https://arxiv.org/abs/1611.07004), which uses a auto 
encoder as a generator to improve the image to image translation.

The input for the generator is the shape of the building and the output is 13 channeled output : 
walls(1), doors(1), windows(1), room types(10)

To train the Generator using GLO run

    python3 glo_train.py --config {path_to_the_config} 
    
> Default config used is [config/glo_train.yaml](config/glo_train.yaml)
>> Each parameter is explained in detail in the yaml file 

Run `python3 train.py --help` to check the available arguments and descriptions.


### Corner model training

A separate corner model is used to train corner detection from walls. To train the model run

    python3 corner_train.py --config {path_to_the_config}

> Default config used is [config/corner_train.yaml](config/corner_train.yaml)
>> Each parameter is explained in detail in the yaml file 


### Model summaries

To know the architecture of the model and the number of parameters run
    
    python3 summary.py

### Tensorboard

Losses and mean, stddev, min and max of generated output and target are stored in summary files 

To view the summary run the following command

    tensorboard --logdir=./summaries
     
